# Pourquoi travailler avec les communautés : une comparaison de l'utilisation de [A-Z+T](https://github.com/kent-rasmussen/azt) avec les méthodes de terrain traditionnelles

Par méthodes de terrain traditionnelles, j'entends celles conçues autour d'un **linguiste formellement formé** qui obtient des données d'un **locuteur linguistiquement naïf d'une langue cible** comme source de données uniquement. C'est la perspective du travail de terrain qui est souvent enseignée dans les cours de méthodes de terrain dans les universités (au moins américaines) et qui s'appuie fortement sur la capacité d'analyse du linguiste formé en dehors de la communauté linguistique. De plus, on ne s'attend généralement pas à accroître la prise de conscience ou la capacité d'analyse du ou des locuteurs naïfs impliqués dans cette recherche ; leur but est simplement de fournir des données.

## Là où les méthodes de terrain traditionnelles sont meilleures

La principale raison pour laquelle les méthodes traditionnelles de terrain sont probablement utilisées est le degré de **contrôle** sur le résultat de ce processus. Si le chercheur n'obtient pas les résultats escomptés, il n'y a personne d'autre à blâmer. Le chercheur peut faire confiance aux transcriptions IPA, car elles sont son propre travail. [A-Z+T](https://github.com/kent-rasmussen/azt) ne collecte pas les jugements basés sur les transcriptions IPA. En supposant que vous les vouliez, vous pouvez transcrire des mélodies sonores après un tri [A-Z+T](https://github.com/kent-rasmussen/azt) (la base des enregistrements multiples que fournit le travail [A-Z+T](https://github.com/kent-rasmussen/azt) ).

## Où [A-Z+T](https://github.com/kent-rasmussen/azt) est meilleur

### Méthodes de recherche participatives

Peut-être que le principal échec des méthodes traditionnelles de terrain, et la principale raison d'utiliser toute méthode participative, est que les méthodes traditionnelles de terrain laissent la communauté là où elle a été trouvée, en termes de compréhension de leur langue. Il peut y avoir un article publié, ou éventuellement un livre, mais les idées peuvent ne pas être partagées avec la communauté qui parle et possède la langue de manière significative. Certains praticiens des méthodes de terrain traditionnelles trouvent un moyen de « redonner » à la communauté, et c'est une bonne chose. Mais les méthodes de recherche participatives associent la communauté à l'analyse, rendant le partage des résultats de la recherche plus organique et moins dépendant d'une rédaction qui vient plus tard (généralement dans une autre langue). Les idées de la recherche participative sont ainsi partagées avec la communauté qui possède la langue, dans certains cas, ayant un impact plus immédiat sur l'alphabétisation et d'autres efforts éducatifs, mais toujours plus longtemps que la présence du linguiste extérieur à la communauté.

### La perspective émique

En plus de ce qui précède (qu'il est tout simplement préférable et plus respectueux d'inclure les gens dans l'analyse de leur langue lorsque cela est possible), il est également vrai (je l'affirme) que vous obtenez de meilleures données lorsque vous regardez une langue à la fois de l'extérieur (étique) **et** du point de vue interne (émique). Il y a toujours des détails phonétiques qu'un étranger pourrait remarquer, tout en reconnaissant qu'ils n'ont aucun impact sur les différences significatives dans la langue. En fait, on pourrait résumer l'objectif principal d'un phonologue en trouvant quelles différences sont significatives *dans la langue* . Oui, il est possible de faire une grande partie de cela par la déduction à partir de faits acquis via la seule perspective étique. Mais il va de soi que si vous voulez savoir ce qui est **important dans une langue** , un locuteur natif de cette langue a une perspective unique et précieuse, que les étrangers ne partagent pas.

Une autre vision de ce point présente la collecte de données en termes de WYSYWYG (ce que vous voyez est ce que vous obtenez), qui a été critiqué comme étant paraphrasé comme "Ce que vous voyez est **tout** ce que vous obtenez". Si nous insistons sur le maintien d'un contrôle strict du processus d'analyse, nous pouvons exclure des perspectives qui ne sont pas immédiatement évidentes pour nous, aussi importantes soient-elles pour la compréhension de la langue.

### Collecte de données organisée depuis le début

Snider (2014) présente un argument solide, fondé sur des principes et théoriquement solide selon lequel nous devons limiter notre enquête sur le ton par catégorie grammaticale, ainsi que par profil de syllabe. Cela a été difficile pour de nombreuses personnes, surtout lorsqu'elles ont compris cela après avoir collecté une grande quantité de données. Mais [A-Z+T](https://github.com/kent-rasmussen/azt) peut faciliter la contrainte de vos données, à la fois dans leur traitement et dans la génération de rapports.

### Archivage des données organisé dès le début

Souvent, les linguistes trouvent les mois qui suivent le travail sur le terrain pleins de données de traitement collectées lors d'une visite sur le terrain. Que faites-vous des heures et des heures d'enregistrements que vous avez pris lors de vos séances de terrain ? Les analysez-vous et les marquez-vous tous, et les mettez-vous dans une base de données consultable ? Si oui, combien de temps cela prend-il ? Ou préférez-vous prendre quelques notes, mais conservez-les essentiellement au cas où vous auriez besoin de vérifier quelque chose qui n'était pas clair dans vos notes ? Mon impression, après avoir discuté avec de nombreux linguistes, est que la plupart n'analysent et n'étiquettent les enregistrements qu'à grands frais, préférant généralement tergiverser, déléguer le travail à un étudiant diplômé ou tout abandonner.

[A-Z+T](https://github.com/kent-rasmussen/azt) , d'autre part, offre une méthode d'enregistrement d'énoncés cibles en peu de temps, qui sont immédiatement et automatiquement étiquetés (par des noms de fichiers significatifs), placés dans un référentiel et liés au [LIFT](https://code.google.com/archive/p/lift-standard/) base de données lexicale — sans aucune charge de temps supplémentaire pour le chercheur ou la communauté. Dès que l'enregistrement est terminé, il en va de même pour l'analyse, la catégorisation et l'organisation.
